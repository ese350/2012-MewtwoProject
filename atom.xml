<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[ReKibilitate]]></title>
  <link href="http://ese350.github.com/MewtwoProject/atom.xml" rel="self"/>
  <link href="http://ese350.github.com/MewtwoProject/"/>
  <updated>2012-04-02T06:10:29-04:00</updated>
  <id>http://ese350.github.com/MewtwoProject/</id>
  <author>
    <name><![CDATA[ReKibilitate]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to set up the Kinect, the easy way ... and the hard way]]></title>
    <link href="http://ese350.github.com/MewtwoProject/blog/2012/03/29/how-to-set-up-the-kinect-the-easy-way-and-the-hard-way/"/>
    <updated>2012-03-29T20:38:00-04:00</updated>
    <id>http://ese350.github.com/MewtwoProject/blog/2012/03/29/how-to-set-up-the-kinect-the-easy-way-and-the-hard-way</id>
    <content type="html"><![CDATA[<p>So as we all know, there are usually two ways of doing things, the
easy way and the hard way. For setting up the Kinect, we erroneously
chose the hard way. Given, when you learn how to work with something
for the first time, it usually takes a while to set up. But when
you&#8217;re working with multiple things at the first time together, then
things get a lot more hectic.</p>

<p>So long story short, we found some tutorials on how to install OpenNI
for the kinect as well as various other dependencies needed to run the
Kinect hardware. These worked and gave us some pretty cool bitmaps
painted onto the screen that varied in color based on depth. Some of
the example code could even track the user and showed a few of their
joints with a little skeleton connecting them. Pretty neat
really. I&#8217;ll post some pictures next time.</p>

<p>This time, I wanted to focus on how to set up the Kinect because that
gave us a whole lot of trouble that could have taken much less
time. For one, don&#8217;t try the following on VMWare Player running an iso
of Ubuntu 11.10. That for sure didn&#8217;t work. And probably VMWare Player
in general? We had some pretty bad luck there. The following
instructions should work on any (newer?) 32-bit Ubuntu distros.</p>

<p>Install dependencies first:</p>

<pre><code>sudo apt-get update
sudo apt-get install g++ python libusb-1.0-0-dev freeglut3-dev openjdk-6-jdk doxygen
</code></pre>

<p>Then install OpenNI:</p>

<pre><code>git clone https://github.com/OpenNI/OpenNI.git
cd OpenNI/Platform/Linux/CreateRedist
chmod a+x RedistMaker
./RedistMaker
cd ../Redist/OpenNI-Bin-Dev-Linux-x86-v1.5.2.23
sudo ./install.sh
</code></pre>

<p>Next up is SensorKinect:</p>

<pre><code>git clone https://github.com/avin2/SensorKinect.git
cd SensorKinect/Bin
tar xvf SensorKinect091-Bin-Linux32-v5.1.0.25.tar.bz2
cd Sensor-Bin-Linux-x86-v5.1.0.25/
sudo ./install.sh
</code></pre>

<p>Now you can plug in the Kinect and run <code>lsusb</code> and check for 3
Microsoft Corp entries. If you see these, you&#8217;ve succesfully installed
everything and the sample code should run on your machine! To test it
out, go to the OpenNI/Platform/Linux/Bin/x86-Release/ folder and run
any of the code in there.</p>

<!-- more -->


<p>And now for the part that a stronger background in Java would have
made so much easier. Go to OpenNI/Platform/Linux/Build/. In here, you
can run <code>make</code> and it&#8217;ll use the <code>Makefile</code> that&#8217;s already set up for
all the code in the <code>Samples</code> directory. If you want to <code>make</code> the bin
files again, you have to type <code>make clean</code> and then <code>make</code> again.</p>

<p>Additionally, you can <code>make</code> each of the Samples individually by
running the same commands when in their Build/Samples/ProjectNameHere/
directory. Meanwhile, the actual source .java files are in the
OpenNI/Samples directory. So if you want to edit the source code or
make a new project, that&#8217;s the place to go. Meanwhile, if you make a
new project, you&#8217;ll have to set up some <code>Makefile</code>s in the Build
folder, but at least you have templates there.</p>

<p>Man how all this knowledge could have helped last night. At least we
got things working and were able to modify the UserTracker program
that can find your joints and calculated a few angles to demonstrate
for the physical therapist today. She seemed to like our demo and
suggested to start with some easy exercises for which to monitor
form. We&#8217;ll see where that takes us and we&#8217;ll try to have something to
show to her again soon.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Meeting with Professor Mangharam: Idea solidified]]></title>
    <link href="http://ese350.github.com/MewtwoProject/blog/2012/03/23/meeting-with-professor-mangharam-idea-solidified/"/>
    <updated>2012-03-23T20:16:00-04:00</updated>
    <id>http://ese350.github.com/MewtwoProject/blog/2012/03/23/meeting-with-professor-mangharam-idea-solidified</id>
    <content type="html"><![CDATA[<p>Today, we met with Professor Mangharam and talked to him about some of
the ideas that we had been throwing around. Turns out, our best ideas
(or at least, the ones that could be spun into some sort of project)
were the ones that we thought of near the end of the night when we
were getting really sleepy.</p>

<p>So what did we decide on? Well, we initially wanted to make some sort
of device that would track form in say, sports such as tennis, running
or weightlifting. He advised us that to go with a medical focus would
make the project more likely to have people interested and mentioned
that he could get in touch with some physical therapists, potentially
making our product actually used in the market. Exciting, huh?</p>

<p>Another fascinating part for me was that we&#8217;d be using a Kinect as the
motion tracker. I always knew video games had lots of use. Now I have
more evidence for my mom.</p>
]]></content>
  </entry>
  
</feed>
